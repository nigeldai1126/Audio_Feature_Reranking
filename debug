# import pandas as pd

# BASELINE = "/scratch/jd5316/Capstone/Capstone/results/lightgcn_base/lightgcn_topk.parquet"
# AUDIO = "/scratch/jd5316/Capstone/Capstone/results/calibration/audio_prefsim_topk.csv"
# POP = "/scratch/jd5316/Capstone/Capstone/Data/sampled/sampled_music_info_with_popularity.csv"

# recs = pd.read_parquet(BASELINE)
# audio = pd.read_csv(AUDIO)
# pop = pd.read_csv(POP)
# print(audio["audio_prefsim"].describe())
# print(audio["audio_prefsim"].std())
# print(pop["popularity"].describe())
# print(pop["popularity"].std())
# print(recs["score"].describe())
# print(recs["score"].std())

# Check your files

import pandas as pd
import os
import json

df = pd.read_parquet("/scratch/jd5316/Capstone/Capstone/results/mmr_latent/lambda_0.1/topk.parquet")


print("\n--- Parquet Columns ---")
print(df.columns)
print(df.head(10))



# import pandas as pd
# import numpy as np
# import json

# # ============================================
# # DIAGNOSTIC: Why is AudioKL infinite and NDCG so low?
# # ============================================

# ITEM_CSV = "/scratch/jd5316/Capstone/Capstone/Data/sampled/sampled_music_info_with_popularity.csv"
# TEST_CSV = "/scratch/jd5316/Capstone/Capstone/results/lightgcn_base/test_internal.csv"
# TRAIN_CSV = "/scratch/jd5316/Capstone/Capstone/results/lightgcn_base/train_internal.csv"
# BASELINE_PARQUET = "/scratch/jd5316/Capstone/Capstone/results/lightgcn_base/lightgcn_topk.parquet"
# ID_MAPPING = "/scratch/jd5316/Capstone/Capstone/results/lightgcn_base/id_mappings.json"

# print("="*80)
# print("DIAGNOSTIC 1: CHECK ITEM METADATA")
# print("="*80)

# item_df = pd.read_csv(ITEM_CSV)
# print(f"\n‚úì Loaded {len(item_df)} items")
# print(f"\nColumns: {item_df.columns.tolist()}")
# print(f"\nData types:")
# print(item_df.dtypes)

# # Check audio features
# audio_features = ["danceability", "energy", "valence", "tempo", "key", "loudness", 
#                   "speechiness", "acousticness", "instrumentalness", "liveness"]
# available_features = [f for f in audio_features if f in item_df.columns]
# missing_features = [f for f in audio_features if f not in item_df.columns]

# print(f"\n‚úì Available audio features ({len(available_features)}): {available_features}")
# if missing_features:
#     print(f"‚úó Missing audio features ({len(missing_features)}): {missing_features}")

# # Check for NaN values
# print(f"\n--- NaN Check ---")
# for col in available_features:
#     nan_count = item_df[col].isna().sum()
#     nan_pct = 100 * nan_count / len(item_df)
#     print(f"  {col}: {nan_count} NaNs ({nan_pct:.1f}%)")

# # Check value ranges
# print(f"\n--- Value Ranges ---")
# for col in available_features[:5]:  # Show first 5
#     print(f"  {col}: [{item_df[col].min():.3f}, {item_df[col].max():.3f}]")

# print("\n" + "="*80)
# print("DIAGNOSTIC 2: CHECK TRAIN/TEST SPLIT")
# print("="*80)

# train_df = pd.read_csv(TRAIN_CSV)
# test_df = pd.read_csv(TEST_CSV)

# print(f"\nTrain: {len(train_df)} interactions")
# print(f"  Users: {train_df['user_id'].nunique()}")
# print(f"  Items: {train_df['track_id'].nunique()}")

# print(f"\nTest: {len(test_df)} interactions")
# print(f"  Users: {test_df['user_id'].nunique()}")
# print(f"  Items: {test_df['track_id'].nunique()}")

# # Check overlap
# train_items = set(train_df['track_id'].unique())
# test_items = set(test_df['track_id'].unique())
# catalog_items = set(item_df['track_id'].unique())

# print(f"\n--- Item Overlap ---")
# print(f"  Items in catalog: {len(catalog_items)}")
# print(f"  Items in train: {len(train_items)}")
# print(f"  Items in test: {len(test_items)}")
# print(f"  Train ‚à© Test: {len(train_items & test_items)} ({100*len(train_items & test_items)/len(test_items):.1f}% of test)")
# print(f"  Test only: {len(test_items - train_items)} cold-start items")
# print(f"  Test items in catalog: {len(test_items & catalog_items)} ({100*len(test_items & catalog_items)/len(test_items):.1f}%)")

# # Cold start ratio
# cold_start_items = test_items - train_items
# if cold_start_items:
#     # Count how many test interactions involve cold items
#     test_df['is_cold'] = test_df['track_id'].isin(cold_start_items)
#     cold_interactions = test_df['is_cold'].sum()
#     print(f"\n  Cold-start test interactions: {cold_interactions}/{len(test_df)} ({100*cold_interactions/len(test_df):.1f}%)")

# print("\n" + "="*80)
# print("DIAGNOSTIC 3: CHECK RECOMMENDATIONS")
# print("="*80)

# # Load mappings
# with open(ID_MAPPING) as f:
#     mapping = json.load(f)

# user_id2token = mapping["id2user"]
# item_id2token = mapping["id2item"]

# print(f"\n--- Mapping Info ---")
# print(f"  User mapping keys (first 10): {list(user_id2token.keys())[:10]}")
# print(f"  Item mapping keys (first 10): {list(item_id2token.keys())[:10]}")
# print(f"  User mapping key types: {type(list(user_id2token.keys())[0])}")
# print(f"  Sample user mapping: '{list(user_id2token.keys())[0]}' ‚Üí '{list(user_id2token.values())[0][:40]}...'")
# print(f"  Sample item mapping: '{list(item_id2token.keys())[0]}' ‚Üí '{list(item_id2token.values())[0]}'")

# # Load baseline recommendations
# rec_df = pd.read_parquet(BASELINE_PARQUET)
# print(f"\n‚úì Loaded {len(rec_df)} recommendations")
# print(f"  Columns: {rec_df.columns.tolist()}")

# # Check ID types in parquet
# print(f"\n--- Parquet ID Info ---")
# print(f"  user_id dtype: {rec_df['user_id'].dtype}")
# print(f"  item_id dtype: {rec_df['item_id'].dtype}")
# print(f"  Sample user_ids (first 10): {rec_df['user_id'].head(10).tolist()}")
# print(f"  Sample item_ids (first 10): {rec_df['item_id'].head(10).tolist()}")
# print(f"  User ID type: {type(rec_df['user_id'].iloc[0])}")
# print(f"  Unique user_ids (first 10): {sorted(rec_df['user_id'].unique())[:10]}")
# print(f"  Unique item_ids (first 10): {sorted(rec_df['item_id'].unique())[:10]}")

# # Try mapping with explicit string conversion
# print(f"\n--- Attempting Mapping ---")
# rec_df["user_id_str"] = rec_df["user_id"].astype(str)
# rec_df["item_id_str"] = rec_df["item_id"].astype(str)

# print(f"  Sample user_id as string: '{rec_df['user_id_str'].iloc[0]}'")
# print(f"  Is it in mapping? {rec_df['user_id_str'].iloc[0] in user_id2token}")

# # Check overlap
# parquet_user_ids = set(rec_df["user_id_str"].unique())
# mapping_user_ids = set(user_id2token.keys())
# overlap_users = parquet_user_ids & mapping_user_ids

# print(f"\n  User IDs in parquet: {len(parquet_user_ids)}")
# print(f"  User IDs in mapping: {len(mapping_user_ids)}")
# print(f"  Overlap: {len(overlap_users)}")

# if len(overlap_users) == 0:
#     print(f"\n  ‚ùå NO OVERLAP! Comparing formats:")
#     print(f"     Parquet user IDs (first 5): {list(parquet_user_ids)[:5]}")
#     print(f"     Mapping user IDs (first 5): {list(mapping_user_ids)[:5]}")

# # Check items too
# parquet_item_ids = set(rec_df["item_id_str"].unique())
# mapping_item_ids = set(item_id2token.keys())
# overlap_items = parquet_item_ids & mapping_item_ids

# print(f"\n  Item IDs in parquet: {len(parquet_item_ids)}")
# print(f"  Item IDs in mapping: {len(mapping_item_ids)}")
# print(f"  Overlap: {len(overlap_items)}")

# if len(overlap_items) == 0:
#     print(f"\n  ‚ùå NO OVERLAP! Comparing formats:")
#     print(f"     Parquet item IDs (first 5): {list(parquet_item_ids)[:5]}")
#     print(f"     Mapping item IDs (first 5): {list(mapping_item_ids)[:5]}")

# # Map to raw IDs
# rec_df["raw_user_id"] = rec_df["user_id_str"].map(user_id2token)
# rec_df["raw_item_id"] = rec_df["item_id_str"].map(item_id2token)

# users_mapped = rec_df["raw_user_id"].notnull().sum()
# items_mapped = rec_df["raw_item_id"].notnull().sum()

# print(f"\n--- Mapping Results ---")
# print(f"  Users mapped: {users_mapped}/{len(rec_df)} ({100*users_mapped/len(rec_df):.1f}%)")
# print(f"  Items mapped: {items_mapped}/{len(rec_df)} ({100*items_mapped/len(rec_df):.1f}%)")

# rec_df = rec_df.dropna(subset=["raw_user_id", "raw_item_id"])

# print(f"  After dropping unmapped: {len(rec_df)} recommendations")

# if len(rec_df) == 0:
#     print("\n  ‚ùå ALL RECOMMENDATIONS DROPPED!")
#     print("     This means parquet IDs don't match mapping keys.")
#     print("\n  üîç POSSIBLE CAUSES:")
#     print("     1. Parquet was generated with OLD mapping")
#     print("     2. Parquet has RAW IDs but we're trying to map them")
#     print("     3. ID format mismatch (int vs string, extra chars, etc.)")
#     import sys
#     sys.exit(1)

# print(f"  Unique users: {rec_df['raw_user_id'].nunique()}")
# print(f"  Unique items: {rec_df['raw_item_id'].nunique()}")

# # Check what items are being recommended
# rec_items = set(rec_df['raw_item_id'].unique())
# print(f"\n--- Recommended Items Analysis ---")
# print(f"  Unique items recommended: {len(rec_items)}")
# print(f"  Recommended items in test: {len(rec_items & test_items)} ({100*len(rec_items & test_items)/len(test_items):.1f}% of test)")
# print(f"  Recommended items in train only: {len(rec_items & train_items - test_items)}")
# print(f"  Recommended items are cold: {len(rec_items & cold_start_items)}")
# print(f"  Recommended items in catalog: {len(rec_items & catalog_items)} ({100*len(rec_items & catalog_items)/len(rec_items):.1f}%)")

# # Sample a user with recommendations
# test_df["raw_user_id"] = test_df["user_id"].astype(str)
# test_df["raw_item_id"] = test_df["track_id"].astype(str)
# user_test = test_df.groupby("raw_user_id")["raw_item_id"].apply(set).to_dict()
# user_recs = rec_df.groupby("raw_user_id")["raw_item_id"].apply(list).to_dict()

# # Find a user with both recs and test items
# overlap_users = set(user_recs.keys()) & set(user_test.keys())
# sample_user = list(overlap_users)[0] if overlap_users else None

# if sample_user:
#     print(f"\n--- Sample User Analysis ---")
#     print(f"  User: {sample_user[:40]}...")
    
#     recs = user_recs[sample_user]
#     test = user_test[sample_user]
    
#     print(f"  Recommendations: {len(recs)} items")
#     print(f"  Test items: {len(test)} items")
#     print(f"  Hits: {len(set(recs[:100]) & test)}")
    
#     # Check if recommended items are in catalog
#     recs_in_catalog = [r for r in recs[:20] if r in catalog_items]
#     test_in_catalog = [t for t in test if t in catalog_items]
    
#     print(f"  Recs in catalog: {len(recs_in_catalog)}/20")
#     print(f"  Test in catalog: {len(test_in_catalog)}/{len(test)}")
    
#     # Check audio features for sample items
#     print(f"\n  Sample recommended items (first 3):")
#     for i, item in enumerate(recs[:3]):
#         if item in catalog_items:
#             has_features = all(item in item_df.set_index('track_id').index and 
#                              not pd.isna(item_df.set_index('track_id').loc[item, f]) 
#                              for f in available_features[:3])
#             print(f"    {i+1}. {item} - in catalog: ‚úì, has features: {'‚úì' if has_features else '‚úó'}")
#         else:
#             print(f"    {i+1}. {item} - in catalog: ‚úó")
    
#     print(f"\n  Sample test items (first 3):")
#     for i, item in enumerate(list(test)[:3]):
#         if item in catalog_items:
#             has_features = all(item in item_df.set_index('track_id').index and 
#                              not pd.isna(item_df.set_index('track_id').loc[item, f]) 
#                              for f in available_features[:3])
#             print(f"    {i+1}. {item} - in catalog: ‚úì, has features: {'‚úì' if has_features else '‚úó'}")
#         else:
#             print(f"    {i+1}. {item} - in catalog: ‚úó")

# print("\n" + "="*80)
# print("DIAGNOSTIC 4: CHECK AUDIO FEATURE COVERAGE")
# print("="*80)

# # Set track_id as index for easier lookup
# item_df_indexed = item_df.set_index('track_id')

# # Check feature coverage for recommended items
# rec_items_list = list(rec_items)[:1000]  # Sample for speed
# rec_in_catalog = [r for r in rec_items_list if r in item_df_indexed.index]

# print(f"\n‚úì Sampled {len(rec_items_list)} recommended items")
# print(f"  In catalog: {len(rec_in_catalog)} ({100*len(rec_in_catalog)/len(rec_items_list):.1f}%)")

# if rec_in_catalog and available_features:
#     feature_coverage = {}
#     for f in available_features:
#         valid_count = item_df_indexed.loc[rec_in_catalog, f].notna().sum()
#         feature_coverage[f] = valid_count / len(rec_in_catalog)
    
#     print(f"\n  Feature coverage (non-NaN):")
#     for f, cov in feature_coverage.items():
#         print(f"    {f}: {cov:.1%}")

# # Check feature coverage for test items
# test_items_list = list(test_items)[:1000]
# test_in_catalog = [t for t in test_items_list if t in item_df_indexed.index]

# print(f"\n‚úì Sampled {len(test_items_list)} test items")
# print(f"  In catalog: {len(test_in_catalog)} ({100*len(test_in_catalog)/len(test_items_list):.1f}%)")

# if test_in_catalog and available_features:
#     feature_coverage = {}
#     for f in available_features:
#         valid_count = item_df_indexed.loc[test_in_catalog, f].notna().sum()
#         feature_coverage[f] = valid_count / len(test_in_catalog)
    
#     print(f"\n  Feature coverage (non-NaN):")
#     for f, cov in feature_coverage.items():
#         print(f"    {f}: {cov:.1%}")

# print("\n" + "="*80)
# print("DIAGNOSTIC COMPLETE")
# print("="*80)

# print("\nüìä SUMMARY:")
# print("="*80)
# print(f"1. Audio features available: {len(available_features)}/{len(audio_features)}")
# print(f"2. Cold-start test items: {len(cold_start_items)}/{len(test_items)} ({100*len(cold_start_items)/len(test_items):.1f}%)")
# print(f"3. Recommended items overlap with test: {len(rec_items & test_items)}/{len(test_items)} ({100*len(rec_items & test_items)/len(test_items):.1f}%)")
# print(f"4. Users with recommendations: {rec_df['raw_user_id'].nunique()}/{test_df['user_id'].nunique()}")
# print("\nüí° Likely issues:")
# if len(cold_start_items) / len(test_items) > 0.5:
#     print("  ‚ö†Ô∏è  HIGH COLD-START RATIO: Over 50% of test items weren't in training")
# if len(rec_items & test_items) / len(test_items) < 0.5:
#     print("  ‚ö†Ô∏è  LOW RECOMMENDATION COVERAGE: Model recommends few test items")
# if len(available_features) < len(audio_features):
#     print(f"  ‚ö†Ô∏è  MISSING AUDIO FEATURES: {missing_features}")

# import pandas as pd

# print(
#      pd.read_parquet("/scratch/jd5316/Capstone/Capstone/results/lightgcn_base/lightgcn_topk.parquet").head(20)
# )

import pandas as pd
from collections import defaultdict
from statistics import mean
p1 = "/scratch/jd5316/Capstone/Capstone/results/xquad/lambda_0.5/topk.parquet"
p2 = "/scratch/jd5316/Capstone/Capstone/results/mmr_latent/lambda_0.6/topk.parquet"

d1 = pd.read_parquet(p1).groupby("user_id")["item_id"].apply(list).to_dict()
d2 = pd.read_parquet(p2).groupby("user_id")["item_id"].apply(list).to_dict()

def jaccard(a,b):
    A,B=set(a),set(b)
    if not A and not B: return 1.0
    return len(A&B)/len(A|B)

jaccs=[]
for u in d1:
    if u in d2:
        jaccs.append(jaccard(d1[u][:100], d2[u][:100]))
print("mean Jaccard overlap:", mean(jaccs))
print("min, max:", min(jaccs), max(jaccs))