This project set out to address two persistent issues in music recommendation: the strong popularity bias that dominates ranked lists and the weak alignment between recommended tracks and users' actual sonic preferences. Through an audio-aware reranking framework that calibrates recommendations to users' historical audio-feature profiles, the system successfully improves both personalization and fairness. The experimental results demonstrate that the method consistently achieves higher NDCG than the baseline and existing rerankers, while also producing the lowest audio KL divergence, indicating substantially better alignment with each user's listening history. At the same time, the reranker increases the proportion of long-tail items without compromising accuracy, showing that it can broaden item exposure while still maintaining strong recommendation quality.

Taken together, these findings show that incorporating audio features directly into the reranking process is an effective way to reduce structural bias and enhance user-centered personalization in music recommender systems. The approach achieves a better balance between accuracy, diversity, and calibration than conventional collaborative-filtering rerankers, demonstrating its practical value in a real-world setting. Future extensions may include integrating temporal listening patterns, contextual user information, or session-based dynamics to further refine calibration. Expanding the method to colder users and exploring more robust popularity estimation would also increase its broader applicability. Overall, this work illustrates the meaningful potential of audio-feature calibration in constructing more balanced, representative, and sonically aligned music recommendation systems.
